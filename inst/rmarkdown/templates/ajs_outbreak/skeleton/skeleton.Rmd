---
title: "AJS outbreak report"
output: 
  word_document:
    keep_md: true
---

# Introduction to this template

This is a template which can be used to create an automated outbreak situation
report for acute jaundice syndrome (AJS). 

- It is organised by time, place and person. 
- You can type normal text in white spaces (such as here) and r-code in grey
    spaces (denoted by three backticks and r) (see [Rmarkdown
    introduction](https://rmarkdown.rstudio.com/articles_intro.html) and
    [Markdown basics](https://rmarkdown.rstudio.com/authoring_basics.html))
- Introductions and contents of sections are within square brackets "[...]" and
    can be deleted as appropriate
- Examples of inline code (to automate updating numbers, e.g. in the "Person
    section"), can similarly be removed/updated
- Code itself can be deleted, but as a word of caution: make sure you aren't
    deleting bits where variables are created/manipulated, or at least update
    them appropriatley
- For a more detailed exaplanation of this template, see [Wiki](https://github.com/R4EPI/sitrep/wiki)
- Feedback and suggestions are welcome at the [GitHub issues page](https://github.com/R4EPI/sitrep/issues)


## Installing and loading required packages 

Several packages are required for different aspects of  analysis with *R*. 
You will need to install these before starting. 
We will be using the following packages. Some of these packages automatically
install other packages they need to work (called dependencies).

These packages can be quite large and may take a while to download in the
field. If you have access to a USB key with these packages, it makes sense to
copy and paste the packages into your computer's R package library 
(run the command .libPaths() to see the folder path). 

For help installing packages, see the [Wiki](https://github.com/R4EPI/sitrep/wiki/1)-Getting-started)

```{r setup, include=FALSE, results='hide', message=FALSE, warning=FALSE}
# hide all code chunks in the output, but show errors
knitr::opts_chunk$set(echo = FALSE,       # hide all code chunks in output
                      error = TRUE,       # show errors if they appear, but don't stop
                      fig.width = 6*1.25, # Figure width
                      fig.height = 6      # Figure height
                     )
# set default NA to - in output, define figure width/height
options(knitr.kable.NA = "-")

# Installing required packages for this template
required_packages <- c("knitr",       # create output docs
                       "dplyr",       # clean/shape data
                       "forcats",     # clean/shape data
                       "stringr",     # clean text
                       "rio",         # read in data
                       "ggplot2",     # create plots and charts
                       "sitrep",      # MSF field epi functions
                       "linelist",    # Functions for cleaning/standardising data
                       "incidence",   # create epicurves
                       "aweek",       # define epi weeks
                       "epitools",    # 2x2 tables and other epi goodness
                       "epitrix",     # epi helpers and tricks
                       "sf",          # encode spatial vector data
                       "ggspatial")   # plot maps

for (pkg in required_packages) {
  # install packages if not already present
  if (!pkg %in% rownames(installed.packages())) {
    install.packages(pkg)
  }
  
  # load packages to this current session 
  library(pkg, character.only = TRUE)
}


# set default text size to 16 for plots
# give classic black/white axes for plots
ggplot2::theme_set(theme_classic(base_size = 18))

# Set the day that defines the beginning of your epiweek.
# you can start the week on any day of the week
# (the ISO standard is to start on Monday) 
aweek::set_week_start("Monday")
```




```{r define_current_week}

# In order to automate your report you need define week of interest (reporting_week)
# This will generally be one week in the past from when you write your report

# define current week 
reporting_week <- "2019-W25"

```




```{r read_fake_data, warning = FALSE, message = FALSE}
# This chunk creates fake data for to use as an example in this template.
# Comment out if you are using real data.
linelist_raw <- gen_data("AJS")
```


```{r read_DHIS_excel_data, warning = FALSE, message = FALSE}

# If your linelist is an excel export of data from DHIS2 use this code chunk
# This assumes your data fits the standardised MSF data dictionary for this
# disease (Otherwise use one of the code chunks below for csv DHIS data and for
# non DHIS data). This script is adapted to fit to DHIS standardised data. 
# If you don't have lab tests or do not wish to create a case definition, 
# then you will need to fix code stratified by case definition later in the script


## Read data ------------------------------------------------------
## When you copy and paste file paths, you need to change \ to /.
##

# USE ONE OF THE BELOW TWO OPTIONS TO READ IN YOUR DATA FROM EXCEL
# one version is for password protected files

## Excel file ---------------------------
#
## To read in a specific sheet use "which"
# linelist_raw <- rio::import("linelist.xlsx", which = "Sheet1")

## Excel file (password-protected) ------
#
## Use the excel.link package 
## The askpass package will prompt you to enter the password

# install.packages(c("excel.link", "askpass"))
# library(excel.link)
# 
# linelist_raw <- xl.read.file("linelist.xlsx",
#                              xl.sheet = "Sheet1",
#                              password = askpass::askpass(prompt = "please enter file password"))

## MSF AJS Dictionary ---------------
## The data dictionary has variable names in the data_element_shortname column. 
## Possible values for each variable are specified in the Code and Name columns.
## Where code has the shortened values and name has the full text values. 

## get MSF data dictionary for AJS 
linelist_dict <- msf_dict("AJS", compact = FALSE) %>%
  select(option_code, option_name, everything())

## you can look at the standard dictionary by uncommenting the line below
# View(linelist_dict) 

## you can view variable names in the standard data dicationry uncommenting the line below
# linelist_dict$data_element_shortname


# Clean column names ---------------------------------------------

## a good first step is to assign standard column names so that subsequent code
## uses stable column names. In case the input data changes, you just need to
## fix the column mapping.

## make a copy of your orginal dataset and name it linelist_cleaned
linelist_cleaned <- linelist_raw

## UNCOMMENT AND RUN TWO LINES OF CODE BELOW!
##
## define clean variable names using clean_labels from the epitrix package. This
## function defines rules for variable naming; for example, it changes spaces
## and dots to "_" and sets all characters to lowercase.

# cleaned_colnames <- epitrix::clean_labels(colnames(linelist_raw))
# colnames(linelist_cleaned) <- cleaned_colnames # overwrite variable names with defined clean names

## OPTIONAL: below is just an example in case you want to specifically change a
## few names you can also change specific var names using the *rename*
## function. In this example, we have the columns "gender" and "age" that we
## want to rename as "sex" and "age_years".
## The formula for this is rename(data, NEW_NAME = OLD_NAME)

# linelist_cleaned <- rename(linelist_cleaned, 
#                            sex       = gender, 
#                            age_years = age)


## OPTIONAL: if you only want to keep certain variables - 
## you can select these by name or column number view the names of your vars
## and their column number using: names(linelist_cleaned) this example keeps
## the first three columns as well as age_years and sex variables

# linelist_reduced <- select(linelist_cleaned, c(1:3, "age_years", "sex"))

## Standardising values --------------------------------------------
## 
## Data entered in through software will often code values in a compact format
## to save space. For example, Yes/No values will often be coded as 1 or 0 and
## sex coded as M or F. This line uses the MSF dictionary to recode these values
## back to a human-readable format.
linelist_cleaned <- clean_variable_spelling(linelist_cleaned,
                                            wordlists = filter(linelist_dict,
                                                               !is.na(option_code)),
                                            spelling_vars = "data_element_shortname",
                                            sort_by = "option_order_in_set"
                                           )
```


```{r read_DHIS_csv_data, warning = FALSE, message = FALSE}

# If your linelist is a csv export of data from DHIS2 use this code chunk
# This assumes your data fits the standardised MSF data dictionary for this disease

## Read data ------------------------------------------------------
## When you copy and paste file paths, you need to change \ to /.
##

# CSV file
# linelist_raw <- rio::import("linelist.csv")

## get MSF data dictionary for AJS 
# linelist_dict <- msf_dict("AJS", compact = FALSE) %>%
#   select(option_code, option_name, everything())

## Fixing variable names ----------------------
## make a copy of your original dataset and name it linelist_cleaned
# linelist_cleaned <- linelist_raw

## define clean variable names using clean_labels from the epitrix package
# cleaned_colnames <- epitrix::clean_labels(colnames(linelist_raw))

## overwrite variable names with excel version names from data dictionary
## return which rows in the data dictionary match your column names

# match_cols <- match(cleaned_colnames, linelist_dict$data_element_name, nomatch = 0)
# cleaned_colnames[match_cols > 0] <- linelist_dict$data_element_shortname[match_cols]

## overwrite variable names with defined clean names
# colnames(linelist_cleaned) <- cleaned_colnames


## Standardising values --------------------------------------------
## 
## Data entered in through software will often code values in a compact format
## to save space. For example, Yes/No values will often be coded as 1 or 0 and
## sex coded as M or F. This line uses the MSF dictionary to recode these values
## back to a human-readable format.
## linelist_cleaned <- switch_vals(df = linelist_cleaned, disease = "AJS")
```



```{r read_nonDHIS_data, warning = FALSE, message = FALSE}

## IF YOUR LINELIST NOT AN EXPORT OF DATA FROM DHIS2 USE THIS CODE CHUNK ------
##
## This assumes your data does not fit the standardised MSF data dictionary for
## this disease. If you are using this section, be aware that this template may
## take more effort due to the unpredictable nature of non-standardized data.
##
## Your data must be in an Excel or CSV file. If your data is in Excel, make
## sure that the Excel sheet is not protected. Many of the old MSF Excel
## templates are in protected sheets.
## If you have a protected sheet, you can save the sheet as a new file.
## This will unprotect the sheet.
##
##
## Checklist to clean and update this script to match your data ---------------
## 
## - [ ] Recode your variable names to match this analysis 
## - [ ] Recode variable contents
## - [ ] Check the code later in the script and update it to fit your names/contents
## - [ ] Make sure to comment out all lines in read_DHIS_excel_data chunk
##
## You will still need to read in the standardised data dictionary
##   This is to understand which variables are being used later in the script
##   So that you can adapt those later code chunks to fit your dataset.
## The data dictionary has variable names in the data_element_shortname column. 
##   Possible values for each variable are specified in the option_code (short
##   values) and option_name (full text) columns.
##
## - [ ] run this to look at the data dictionary: 
# linelist_dict <- msf_dict("AJS", compact = FALSE) %>%
#   select(option_code, option_name, everything())
# View(linelist_dict) 


## Read data ------------------------------------
## When you copy and paste file paths, you need to change \ to /.
##

# Excel file
# to read in a specific sheet use "which"
# linelist_raw <- rio::import("linelist.xlsx", which = "Sheet1")


# Excel file -- Specific range
# You can specify a range in an excel sheet where your data are.
# linelist_raw <- rio::import("linelist.xlsx", range = "B2:J102")


# Excel file -- password protected
# Use the excel.link package to load the file.
#   The askpass package will prompt you to enter the password every time.
# install.packages(c("excel.link", "askpass"))
# library(excel.link)
# 
# linelist_raw <- xl.read.file("linelist.xlsx",
#                              xl.sheet = "Sheet1",
#                              password = askpass::askpass(prompt = "please enter file password"))


# CSV file
# linelist_raw <- rio::import("linelist.csv")


# Stata data file
# linelist_raw <- rio::import("linelist.dat")



## Fixing variable names ----------------------

## make a copy of your orginal dataset and name it linelist_cleaned
# linelist_cleaned <- linelist_raw

# clean variable names using clean_labels from the epitrix package
# this function has preset rules for variable naming 
# for example it changes spaces and dots to "_" and characters to lowercase
# cleaned_colnames <- epitrix::clean_labels(colnames(linelist_raw))

# overwrite variable names with defined clean names
# colnames(linelist_cleaned) <- cleaned_colnames

## Renaming variables to match the template -------------------------------
## OPTIONAL: below is just an example in case you want to specifically change a
## few names you can also change specific var names using the *rename*
## function. In this example, we have the columns "gender" and "age" that we
## want to rename as "sex" and "age_years".
## The formula for this is rename(data, NEW_NAME = OLD_NAME). 

# linelist_cleaned <- rename(linelist_cleaned, 
#                            sex       = gender, # TEXT
#                            age_years = age     # INTEGER_POSITIVE
# )

## You can use the function msf_dict_rename_helper() to create a template based
## on the AJS dictionary. 
# This will copy a rename command like the one above
## to your clipboard.
# msf_dict_rename_helper("AJS")
## Paste the result here and add add the column names from linelist_cleaned
## to the appropriate variables. PLEASE NOTE: this is not a foolproof solution;
## you still need to be aware of what each variable means and what values it
## takes. 
## 
## If there are any variables that are in the MSF dictionary that are not in
## your data set, then you should comment them out, but be aware that some
## analyses may not run because of this. 

## OPTIONAL: 
## If you only want to keep certain variables - 
## you can select these by name or column number view the names of your vars
## and their column number using: names(linelist_cleaned) this example keeps
## the first three columns as well as age_years and sex variables.
##
## You can also use this to create temporary datasets to review.

# linelist_reduced <- select(linelist_cleaned, c(1:3, "age_years", "sex"))
```








```{r read_population_data, warning = FALSE, message = FALSE}


## USE THIS TO READ IN POPULATION OR TO CREATE IT FROM PROPORTIONS  -----------
##
## There are two options for using population data here. 
## The first one is where you only know the total population number, and the 
## proportion breakdown for categories (e.g. by age group, sex or region). 
## The second option is to read in population from excel. 
## In both cases you will need to make sure that the respective groups for 
## population fit the groups in your linelist data set!
##
## Checklist for population data ----------------------------------------------
## 
## - [ ] Decide if you have stratified population data available as counts or only proportions
## - [ ] If you have counts available:
##          - [ ] use View on the fake data generated to make sure your format in excel matches
##          - [ ] read in and clean data appropriately in the "Read data" section
##          - [ ] make sure the groups match the appropriate variable in your linelist!
## - [ ] If have total population and proportion breakdown available: 
##          - [ ] use the gen_population function in "counts from populaiton proportions" section
##          - [ ] type in your population, groups, and respective proportions
##          - [ ] group can be any categorical variable you want
##          - [ ] make sure the groups match the appropriate variable in your linelist!
## - [ ] DELETE OR COMMENT OUT THE UNUSED SECTION


## Read data ------------------------------------
## When you copy and paste file paths, you need to change \ to /.
##

## Excel file
## to read in a specific sheet use "which"
# population_data <- rio::import("population.xlsx", which = "Sheet1")

## repeat same cleaning steps as in standardise_clean_data code chunk as appropriate
## make sure your place variable name matches!

## Counts from population proportions ------------------------------------ 
## if you only know the total population and the proportions in each age group, use this function 


# generate population data by region 
population_data_region <- gen_population(total_pop = 5000,         # set the total population 
  groups = c("Village A", "Village B", "Village C", "Village D"),  # set the groups 
  proportions = c(0.221, 0.174, 0.355, 0.245),                     # set the proportions for each group
  strata = NULL) %>%               # do not stratify by gender 
  rename(patient_origin = groups,  # rename columns (syntax is NEW NAME = OLD NAME)
         population = n)

# generate population data by age groups in years 
population_data_age <- gen_population(total_pop = 5000,
  groups = c("0-2", "3-14", "15-29", "30-44", "45+"),
  proportions = c(0.182, 0.278, 0.26, 0.11, 0.07),
  strata = NULL) %>%
  rename(age_group = groups,
    population = n)

# generate population data by age group in months (under 2 years) 
population_data_age_months <- gen_population(total_pop = 5000,
  groups = c("0-5", "6-8", "9-11","12-24"),
  proportions = c(0.278, 0.11, 0.18, 0.26),
  strata = NULL) %>%
  rename(age_group_mon = groups,
    population = n)


# generate population data by age categories in months and years 
# population_data_age_categories <- gen_population(total_pop = 5000,
#   groups = c("0-5 months", "6-8 months", "9-11 months","12-24 months",
#              "3-14 years", "15-29 years", "30-44 years", "45+ years"),
#   proportions = c(0.278, 0.11, 0.18, 0.26, 0.278, 0.26, 0.11, 0.07),
#   strata = NULL) %>%
#   rename(age_category = groups,
#     population = n)
```


```{r lab_data}
## OPTIONAL: this section can be used to read in lab data
## make sure that your unique identifiers (e.g. case_number) match with the linelist! 
## - [ ] DELETE THE FAKE DATA SECTION!!

## Read data ------------------------------------
## When you copy and paste file paths, you need to change \ to /.
##

## Excel file
## to read in a specific sheet use "which"
# lab_data <- rio::import("labresults.xlsx", which = "Sheet1")

## repeat same cleaning steps as in standardise_clean_data code chunk as appropriate
## make sure your unique ID variable name matches!

## Fake data ------------------------------------ 
## THE BELOW CAN BE DELETED IF YOU HAVE YOUR OWN (REAL) LABORATORY DATA! 
## its just to be able to demonstrate script in this template

# # generate artificial lab tests results
# lab_results <- linelist_cleaned %>% 
#                 select(case_number) %>% 
#                 mutate(test_result = sample(c("Positive", "Negative"),
#                                             nrow(linelist_cleaned), 
#                                             replace = TRUE)
#                        )
# 
# # merging linelist with lab dataset 
# linelist_cleaned <- left_join(linelist_cleaned, lab_results, 
#                               by = "case_number")
```




```{r browse_data, eval = FALSE}
## Browsing data ---------------------------------
## here are a few ways to do data explorations 

## view the first ten rows of data
head(linelist_cleaned, n = 10)

## view your whole dataset interactivley (in an excel style format)
## Remember that `View` needs to be written with a capital *V*
View(linelist_cleaned)

## overview of variable types and contents
str(linelist_cleaned)

## gives mean, median and max values of variables
## gives counts for categorical variables
## also gives number of NAs
summary(linelist_cleaned)

## view unique values contained in variables 
unique(linelist_cleaned$sex)

## another alternative is with the "summarytools package"
## use the dfSummary function in combination with view
## note that view is not capitalised with this package
# install.packages("summarytools")
# summarytools::view(summarytools::dfSummary(linelist_cleaned))
```





```{r standardise_clean_data}

## USE THIS TO CREATE AND CLEAN VARIABLES IN YOUR DATA  -----------------------
##
## All your data cleaning and new variable creation should happen in this chunk. 
## This way, if you mess up all you have to do is push the small arrow at the
## top of this chunk between the cogg and the play buttons, to run all the 
## code chunks up to the current one, then continue your cleaning from where you
## started. 
## 
## YOU WILL NEED TO ADAPT THIS SECTION ACCORDING TO YOUR DATA!
## 
## currently there are examples of cleaning for: 
##    - Date variables 
##    - Numeric variables 
##    - Categorical variables from numerics (e.g. age groups) 
##    - Factor variables (for creating/manipulating categorical variables)
##


# Drop unused rows  ---------------------------------
# Your data might have rows that are blank besides ID number.
# The below keeps variables only with a case ID and an admission date.
linelist_cleaned <- linelist_cleaned %>% 
  filter(!is.na(case_number) & !is.na(date_of_consultation_admission)) 


# Date variables ---------------------------------
# IF YOU ARE USING THE DATA DICTIONARY USE THIS OTHERWISE UNCOMMENT LINES BELOW
# make sure all date variables are formatted as dates 
DATEVARS <- filter(linelist_dict, data_element_valuetype == "DATE") %>%
  filter(data_element_shortname %in% names(linelist_cleaned)) %>% 
  # filter to match the column names of your data
  pull(data_element_shortname) 

# change to dates 
linelist_cleaned <- linelist_cleaned %>%
  mutate_at(DATEVARS, linelist::guess_dates,
            error_tolerance = 0.5)

# if you dont have a data dictionary you could do it this way too
# linelist_cleaned <- linelist_cleaned %>%
#   mutate_at(vars(matches("date|Date")), linelist::guess_dates,
#           error_tolerance = 0.5)


# set unrealistic dates to NA, based on having browsed dates in the previous chunk
# these are just examples -- examine your data and edit as needed
# linelist_cleaned <- mutate(linelist_cleaned,
#                            date_of_onset = case_when(
#                              date_of_onset < as.Date("2017-11-01")  ~ as.Date(NA),
#                              date_of_onset == as.Date("2081-01-01") ~ as.Date("2018-01-01"),
#                              TRUE                                   ~ date_of_onset
#                            ))
  
# create an epiweek variable
# floor_day shortens to only give you the week number (rather than including day as well) 
# factor includes all weeks between the min and max as levels (useful for zero count weeks)
linelist_cleaned$epiweek <- aweek::date2week(linelist_cleaned$date_of_onset, 
                                             floor_day = TRUE, 
                                             factor = TRUE)


# Numeric variables --------------------------------- 
# create number of days under observation
linelist_cleaned <- mutate(linelist_cleaned, 
                           obs_days = as.numeric(date_of_exit - date_of_consultation_admission))


# Age group variables ---------------------------------

## OPTIONAL: add under 2 years to the age_years variable
## data dictionary defines that under 2s dont have year filled in (but months/days instead)
linelist_cleaned <- linelist_cleaned %>% 
  mutate(age_months = case_when(
    is.na(age_years) & is.na(age_months) ~ as.numeric(age_days / 30), 
    TRUE                                 ~ as.numeric(age_months)
  ),
    age_years = case_when(
    is.na(age_years) & is.na(age_months) ~ as.numeric(age_days / 365.25),
    is.na(age_years)                     ~ as.numeric(age_months / 12),
    TRUE                                 ~ as.numeric(age_years)
  ))


## OPTIONAL: change those who are above or below a certain age to NA
# linelist_cleaned <- mutate(linelist_cleaned,
#                            age_years = case_when(
#                              is.na(age_years) ~ NA_integer_,
#                              age_years < 0   ~ NA_integer_,
#                              age_years > 120 ~ NA_integer_,
#                              TRUE            ~ as.integer(age_years) #Preserves other values
#                            ))

## OPTIONAL: create an age_months variable from decimal years variable
# linelist_cleaned <- mutate(linelist_cleaned,
#                            age_months = case_when(
#                              age_years < 5 ~ age_years * 12
#                              )) 


## create age group variable for under 5 years based on months
linelist_cleaned$age_group_mon <- age_categories(linelist_cleaned$age_months, 
                                                 breakers = c(0, 6, 9, 12, 24), 
                                                 ceiling = TRUE)

## create an age group variable by specifying categorical breaks
linelist_cleaned$age_group <- age_categories(linelist_cleaned$age_years, 
                                             breakers = c(0, 3, 15, 30, 45))



## alternatively, create an age group variable specify a sequence
# linelist_cleaned$age_group <- age_categories(linelist_cleaned$age,
#                                              lower = 0, 
#                                              upper = 100, 
#                                              by = 10)

## If you already have an age group variable defined, you should manually
## arrange the categories
# linelist_cleaned$age_group <- factor(linelist_cleaned$age_group,
#                                      c("0-4y", "5-14y", "15-29y", "30-44y", "45+y"))


## to combine different age categories use the following function 
## this prioritises the smaller unit, i.e. if given months and years, will return months first
## generally, these delineations are NOT used for AJS.
##
# linelist_cleaned <- group_age_categories(linelist_cleaned, 
#                                          years = age_group, 
#                                          months = age_group_mon)
# # drop the 0-2 years age level! (need to fix group_age_categories)
# linelist_cleaned <- linelist_cleaned %>% 
#   mutate(age_category = factor(age_category, 
#                                 levels = c("0-5 months",
#                                            "6-8 months",
#                                            "9-11 months",
#                                            "12-24 months",
#                                            "3-14 years",
#                                            "15-29 years",
#                                            "30-44 years", 
#                                            "45+ years")))

# Factor (categorical) variables ---------------------------------

## create a new variable from another character/factor variable
## create a binary variable if patients died 
## use this version if you have named values 
## (e.g. "Dead on arrival" or "Dead in facility")
## alternatively use the version below
linelist_cleaned$DIED <- grepl("Dead", linelist_cleaned$exit_status)

## use this version for coded values (e.g. "DOA", "DD")
# linelist_cleaned$DIED <- linelist_cleaned$exit_status %in% c("DD", "DOA"))

# create a new grouping for exit status variable 
linelist_cleaned <- linelist_cleaned %>% 
  mutate(exit_status2 = case_when(
    exit_status %in% c("Dead on arrival", "Dead in facility") ~ "Died",
    exit_status %in% c("Transferred (to an MSF facility)", 
                       "Transferred (to External Facility)")  ~ "Transferred",
    exit_status == "Discharged home"                          ~ "Discharged",
    exit_status == "Left against medical advice"              ~ "Left"
  ))

## recode a character variable
## fix any misspellings in the manually entered geographic region variables
## you can choose any geographic region which you have available to you 
## ideally this variable would fit your shapefile and population data! 
## If you have many regions - consider group by an overarching unit (e.g. province)
# linelist_cleaned <- linelist_cleaned %>%
#   mutate(patient_origin_free_text = fct_recode(patient_origin_free_text,
#     # List all incorrect mis-spellings here ("new" = "old")
#     "Village D" = "Valliages DD",
#     "Village D" = "Villiage D"
#   ))

## sometimes, coding is inconsistent across variables -- for example, "Yes" / "No"
## may be coded as Y, y, yes, 1 / N, n, no, 0. You can change them all at once!
## Create a list of the variables you want to change, and run the following.
## You may need to edit this code if options are different in your data.

# # create list of variables
# change_yn <- c("headache", "fever", "vomiting")
# 
# # standardize options
 # linelist_cleaned <- linelist_cleaned %>%  
 #      mutate_at(vars(change_yn), forcats::fct_recode,   
 #      Yes = "y",  
 #      Yes = "Y",  
 #      Yes = "yes",  
 #      Yes = "1",   
 #      No  = "n",  
 #      No  = "N",  
 #      No  = "no",  
 #      No  = "0",  
 #    )     
  


# Force missing values to NA
# important for sex to generate age pyramids
linelist_cleaned$sex <- fct_recode(linelist_cleaned$sex, 
                                   NULL = "Unknown/unspecified")


# change the order of levels in a single categorical variable 
linelist_cleaned <- linelist_cleaned %>% 
  mutate(time_to_death = factor(time_to_death, 
                                levels = c("0-4 hours", 
                                           ">4-24 hours", 
                                           ">24-48 hours", 
                                           ">48 hours")))

# Change the order of levels of multiple categorical variables
linelist_cleaned <- linelist_cleaned %>%
  mutate_at(vars(starts_with("test")),          # Looks for variables beginning with "test"
            fct_relevel,
            "Positive", "Negative", "Not done"  # Sets order of levels
           )

# Create a variable based on rules from other simple character variables
# If you have access to lab results, you can create a case definition variable 
# the tilda (~) is used to assign the new values (Conf, prob, susp, unknown)
# starting from the specific to the general
# TRUE assigns all remaining rows 
# You MUST modify this section to match your case definition. The below
# uses positive RDT for Confirmed and epi link only for Probable.
#
linelist_cleaned <- linelist_cleaned %>%
  mutate(case_def = case_when(
    is.na(hep_e_rdt) & is.na(other_cases_in_hh)           ~ NA_character_,
    hep_e_rdt == "Positive"                               ~ "Confirmed",
    hep_e_rdt != "Positive" & other_cases_in_hh == "Yes"  ~ "Probable",
    TRUE                                                  ~ "Suspected"
  ))

# vectors of variable names ----------------------------------------------------

## You may want to group the names of several variables that have the same possible 
## values in to a named vector. 
## This way if you want to run the same function over these variables you can 
## simply use the named vector rather than typing out each variable individually

# create a grouping of all symptoms 
SYMPTOMS <- c("generalized_itch", 
              "history_of_fever", 
              "fever",
              "joint_pains",
              "epigastric_pain_heartburn",
              "nausea_anorexia",
              "vomiting", 
              "diarrhoea",
              "bleeding", 
              "headache",
              "mental_state",
              "convulsions",
              "other_symptoms"  
              )

# create a grouping of all lab tests 
LABS <- c("hep_b_rdt", 
          "hep_c_rdt",
          "hep_e_rdt",
          "test_hepatitis_a",
          "test_hepatitis_b",
          "test_hepatitis_c",
          "test_hepatitis_e_igg",
          "test_hepatitis_e_igm" ,
          "test_hepatitis_e_genotype",
          "test_hepatitis_e_virus",
          "malaria_rdt_at_admission",
          "malaria_blood_film", 
          "dengue",
          "dengue_rdt", 
          "yellow_fever",
          "typhoid",
          "chikungunya_onyongnyong", 
          "ebola_marburg",
          "lassa_fever",
          "other_arthropod_transmitted_virus", 
          "other_pathogen"
          )

# Dropping observations (rows) and variables (columns)--------------------------

# drop cases after reporting week
linelist_cleaned <- linelist_cleaned %>% 
  filter(date_of_consultation_admission <= week2date(sprintf("%s-7", reporting_week)))

# define the first week of outbreak (date of first case)
first_week <- levels(linelist_cleaned$epiweek)[1]

# outbreak start 
# return the first day in the week of first case 
obs_start <- week2date(sprintf("%s-1", first_week))

# return last day of reporting week 
obs_end   <- week2date(sprintf("%s-7", reporting_week))

# OPTIONAL: drop several variables you might not want
# the negative sign before the "c"" in select drops those variables
# without the negative you would only keep the names variables
# linelist_cleaned <- linelist_cleaned %>%
#   select(-c(msf_involvement, treatment_facility_site))

```



```{r save_cleaned_data, eval = FALSE}
## OPTIONAL: save your cleaned dataset! 
## put the current date in the name so you know!
# rio::export(linelist_cleaned, paste0("linelist_cleaned_", Sys.Date(), ".xlsx"))
```



### Person

* [Who is affected: how many in total; male or female; young, adult or old? What are the links between affected people â€“ work place, school, social gathering?  Is there a high rate of illness in contacts?  Is there a high rate of illness in a specific group of people (e.g. health workers)? You may want to include:  a bar chart showing case numbers or incidence by age group and sex; attack rates (AR); and numbers of deaths (in suspected and confirmed cases), mortality rates and/or case fatality ratio (CFR)]  


From the start of the outbreak up until `r reporting_week` there were a 
total of `r nrow(linelist_cleaned)` cases. There were
`r fmt_count(linelist_cleaned, sex == "Female")` females and
`r fmt_count(linelist_cleaned, sex == "Male")` males. 

The most affected age group was `r tab_linelist(linelist_cleaned, age_group) %>% slice(which.max(n)) %>% pull(value)` years. 


#### Demographics 



Cases by age group and definition 

```{r describe_by_age_group_and_def}
# use if you have lab results in your data
# creates table of cases by age group and case definition

tab_linelist(linelist_cleaned, 
             # rows as age groups, with case_def as strata (columns)
             age_group, strata = case_def, 
             # we want row totals and column totals
             col_total = TRUE, row_total = TRUE) %>%
  
  # removes the column called variable (which just says "age_group" in this case)
  select(-variable) %>%
  
  # renames the column called value to Age group
  rename("Age group" = value) %>%
  
  # there are several columns called "proportion" - renames them to %
  rename_redundant("%" = proportion) %>%
  
  # any time there is a column that says n, we replace that with "cases (n)"
  augment_redundant(" cases (n)" = " n$") %>%
  
  # makes the table easy to read with only 2 decimal places
  kable(digits = 2)
```


Alternatively if you would like proportions to be of the total population, use the following. 

```{r total_props_agegroup_sex}
tab_linelist(linelist_cleaned, 
             age_group, strata = sex,
             col_total = TRUE, row_total = TRUE, prop_total = TRUE) %>% 
  select(-variable) %>%
  rename("Age group" = value) %>%
  rename_redundant("%" = proportion) %>%
  augment_redundant(" cases (n)" = " n$") %>%
  kable(digits = 2)
```


Age pyramid 

There were `r fmt_count(linelist_cleaned, is.na(sex))` cases missing information on sex and 
`r fmt_count(linelist_cleaned, is.na(age_group))` missing age group.

```{r age_pyramid, warning=FALSE}
# plot age pyramid 
 plot_age_pyramid(linelist_cleaned,
                  age_group = "age_group", 
                  split_by = "sex") + 
  labs(y = "Cases (n)", x = "Age group") + # change axis  labels (nb. x/y flip)
  theme(legend.position = "bottom",     # move legend to bottom
        legend.title = element_blank(), # remove title
        text = element_text(size = 18)  # change text size
       )
```



```{r age_pyramid_under_two, warning=FALSE}
# plot age pyramid under 2s
filter(linelist_cleaned, age_years <= 2) %>%
  plot_age_pyramid(age_group = "age_group_mon",
                   split_by = "sex") +
                  # stack_by = "case_def") +
  labs(y = "Cases (n)", x = "Age group (months)") + # change axis  labels (nb. x/y flip)
  theme(legend.position = "bottom",     # move legend to bottom
        legend.title = element_blank(), # remove title
        text = element_text(size = 18)  # change text size
       )
```

Of the patients, `r fmt_count(linelist_cleaned, patient_facility_type == "Outpatient")` were seen as outpatients and `r fmt_count(linelist_cleaned, patient_facility_type == "Inpatient")` were inpatients. Among inpatients, the median number of days admitted was `r median(linelist_cleaned$obs_days, na.rm = T)`, 
with a range between `r min(linelist_cleaned$obs_days, na.rm = T)` and `r max(linelist_cleaned$obs_days, na.rm = T)` days.


Cases by symptoms. 

```{r describe_by_symptoms}

# get counts and proportions for all variables named in SYMPTOMS
tab_linelist(linelist_cleaned, SYMPTOMS, keep = "Yes") %>% 
  select(-value) %>%
  # fix the way symptom names are displayed - remove the _ and make the first letter uppercase
  mutate(variable = str_to_sentence(gsub("_", " ", variable))) %>%
  # rename accordingly
  rename_redundant("%" = proportion) %>%
  augment_redundant(" (n)" = " n$") %>%
  kable(digits = 2)
```

Cases by lab results 

```{r describe_by_labs}
# get counts and proportions for all variables named in LABS
tab_linelist(linelist_cleaned, LABS, 
             transpose = "value") %>% 
  # fix the way lab test names are displayed
  mutate(variable = str_to_sentence(gsub("_", " ", variable))) %>%
  # rename accordingly
  rename("Lab test" = variable) %>%
  rename_redundant("%" = proportion) %>%
  augment_redundant(" (n)" = " n$") %>%
  kable(digits = 2)

```




#### Case fatality ratio 

Of `r fmt_count(linelist_cleaned, patient_facility_type == "Inpatient")` inpatients, there have been `r fmt_count(linelist_cleaned, grepl("Dead", exit_status), patient_facility_type == "Inpatient")` deaths, of which 
`r fmt_count(linelist_cleaned, exit_status == "Dead on arrival")` 
were dead on arrival. 

Among inpatients who died, the time to death is shown below. 

```{r describe_time_to_death, warning = FALSE, message = FALSE}
filter(linelist_cleaned, DIED, patient_facility_type == "Inpatient") %>% 
  tab_linelist(time_to_death, col_total = TRUE) %>% 
  select(-variable) %>%
  rename("Time (hours)" = value, 
         "Deaths (n)" = n, 
         "%" = proportion) %>% 
  kable(digits = 2)
```



The case fatality ratio among inpatients with known outcomes is below.

```{r overall_cfr, warning = FALSE, message = FALSE}
# use arguments from above to produce overal CFR
overall_cfr <- linelist_cleaned %>% 
  filter(patient_facility_type == "Inpatient") %>%
  case_fatality_rate_df(deaths = DIED, mergeCI = TRUE) %>%
  rename("Deaths" = deaths,
         "Cases" = population,
         "CFR (%)" = cfr,
         "95%CI" = ci)

  knitr::kable(overall_cfr, digits = 2)         # print nicely with 2 digits
```


The case fatality ratio by sex among inpatients with known outcomes is below. 

```{r cfr_by_sex, warning = FALSE, message = FALSE}
linelist_cleaned %>%
  filter(patient_facility_type == "Inpatient") %>%
  mutate(sex = forcats::fct_explicit_na(sex, "-")) %>%
  case_fatality_rate_df(deaths = DIED, group = sex, mergeCI = TRUE, add_total = TRUE) %>%
  rename("Sex" = sex, 
         "Deaths" = deaths, 
         "Cases" = population, 
         "CFR (%)" = cfr, 
         "95%CI" = ci) %>% 
  knitr::kable(digits = 2)
```



CFR by age group among inpatients with known outcomes

```{r cfr_by_age_group, warning = FALSE, message = FALSE}

linelist_cleaned %>%
  filter(patient_facility_type == "Inpatient") %>%
  case_fatality_rate_df(deaths = DIED, group = age_group, mergeCI = TRUE, add_total = TRUE) %>%
  tidyr::complete(age_group, 
                  fill = list(deaths = 0, 
                              population = 0, 
                              cfr = 0, 
                              ci = 0)) %>% # Ensure all levels are represented
  rename("Age group" = age_group, 
         "Deaths" = deaths, 
         "Cases" = population, 
         "CFR (%)" = cfr, 
         "95%CI" = ci) %>% 
  knitr::kable(digits = 2)
```



```{r cfr_by_case_def, warning = FALSE, message = FALSE}
# Use if you have enough confirmed cases for comparative analysis 
#
# linelist_cleaned %>%
#   filter(patient_facility_type == "Inpatient") %>%
#   case_fatality_rate_df(deaths = DIED, group = case_def, mergeCI = TRUE, add_total = TRUE) %>%
#   rename("Case definition" = case_def, 
#          "Deaths" = deaths, 
#          "Cases" = population, 
#          "CFR (%)" = cfr, 
#          "95%CI" = ci) %>% 
#   knitr::kable(digits = 2)
```


#### Attack rate

The attack rate per 10,000 population is below (based on available population data available for the catchment area/region of interest). 

```{r collect_variables}
# define population 
population <- sum(population_data_age$population)
```

Below gives the attack rate per 10,000 population (N = `r format(population, big.mark = ",")`)
```{r attack_rate}
# calculate the ar
# store as AR to be able to use output for automating text below (inline functions)
ar <- attack_rate(nrow(linelist_cleaned), population, multiplier = 10000)

ar %>%
  merge_ci_df(e = 3) %>% # merge the lower and upper CI into one column
  rename("Cases (n)" = cases, 
         "Population" = population, 
         "AR (per 10,000)" = ar, 
         "95%CI" = ci) %>% 
  select(-Population) %>% # drop the population column as it is not changing
  knitr::kable(digits = 2, align = "r")
```

Here, we can see that the attack rate for a population of `r format(population, big.mark = ",")` was `r fmt_ci_df(ar, percent = FALSE)`.

To give attack rate by age group, with appropriate population denominators, use the following code. 

```{r attack_rate_by_agegroup, warning = FALSE}

cases <- count(linelist_cleaned, age_group) %>%    # cases for each age_group
  left_join(population_data_age, by = "age_group") # merge population data 

# attack rate for each week
attack_rate(cases$n, cases$population, multiplier = 10000, mergeCI = TRUE) %>% 
  # add the epiweek column to table
  bind_cols(select(cases, age_group), .) %>% 
  rename("Age group" = age_group, 
         "Cases (n)" = cases, 
         "Population" = population, 
         "AR (per 10,000)" = ar, 
         "95%CI" = ci) %>% 
  kable(digits = 2, format.args = list(big.mark = ",")) # set thousands separator
```


#### Mortality attributable to AJS

THIS WHOLE MORTALITY SECTION SHOULD BE DELETED UNLESS YOU ARE IN 
A CLOSED SETTING (e.g. refugee camp). 
The assumptions don't hold in an open/community setting.

This section gives mortality rates attributable to AJS in a closed population. 
It does not calculate all-cause mortality. It assumes that all AJS deaths are 
among inpatients.

This demonstrates three ways of calculating mortality rate based on 
catchment population (twice) and based on hospital population. 

```{r collect_variables_rates}
# count number of deaths 
deaths <- sum(linelist_cleaned$DIED)

# outbreak duration in days 
obs_time <- as.numeric(obs_end - obs_start)

# patient observation time 
pat_obs_time <- linelist_cleaned %>% 
  filter(!is.na(exit_status)) %>% 
  summarise(days = sum(obs_days)) %>%
  pull(days)
```

To produce a mortality rate (attribuatble to AJS) per 10,000 people use the 
following code chunk. 
This assumes that you are capturing every AJS death in your population. 

```{r mortality_rate}
mortality_rate(deaths, population, multiplier = 10000, mergeCI = TRUE) %>%
  rename("Deaths" = deaths, 
         "Population" = population, 
         "Mortality (per 10,000)" = `mortality per 10 000`, 
         "95%CI" = ci) %>% 
  kable(digits = 2)
```

To produce a crude mortality rate attributable to AJS per 10,000 people per 
day, use the folowing code chunk. 
This assumes that you are capturing every AJS death in your population and 
that your population remains stable over the time period of interest. 
In this situation the time period of interest is from the beginning of the 
epiweek your first case occured in, until the last day of the epiweek you are 
currently reporting on. (see this [presentation](https://www.odi.org/sites/odi.org.uk/files/odi-assets/events-presentations/776.pdf) for more detail)


```{r mortality_rate_CMR}
mortality_rate(deaths, population*obs_time, multiplier = 10000, mergeCI = TRUE) %>%
  rename("Deaths" = deaths, 
         "Person-days" = population, 
         "Mortality (per 10,000/day)" = `mortality per 10 000`, 
         "95%CI" = ci) %>% 
  kable(digits = 2)
```

Alternatively, if you are unsure whether your hospital deaths are
representative of the wider population, use the following code chunk. 
This uses the person days of cases in your linelist with a known outcome. 
However, this will give you an unreasonably high mortality rate, as 
those in hospital will only be the most severely affected. 

```{r mortality_rate_patients}
mortality_rate(deaths, pat_obs_time, multiplier = 10000, mergeCI = TRUE) %>%
  rename("Deaths" = deaths, 
         "Population" = population, 
         "Mortality (per 10,000/day)" = `mortality per 10 000`, 
         "95%CI" = ci) %>% 
  kable(digits = 2)
```


### Time

* [When did the cases fall ill? Are numbers increasing or stable? You may want to include an Epi curve (bar chart showing number of new (suspected and confirmed) cases each day/week) ]

There were `r fmt_count(linelist_cleaned, is.na(date_of_onset))` cases missing dates of onset. 

```{r create_incidence, message = FALSE}
# This code creates case counts for each week of your outbreak, overall
# As with aweek, you can change the start of your week to e.g. "Sunday week"
inc_week_7 <- incidence(linelist_cleaned$date_of_onset, interval = "Monday week")

# this sets the theme in ggplot for epicurves
epicurve_theme <- theme(
  axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1), 
  legend.title = element_blank(),
  panel.grid.major.x = element_line(color = "grey60", linetype = 3),
  panel.grid.major.y = element_line(color = "grey60", linetype = 3)
)
# This sets the labels in ggplot for the epicurves
epicurve_labels <- labs(x = "Calendar week", 
                        y = "Cases (n)", 
                        title = "Cases by week of onset",
                        subtitle = sprintf("Source: MSF data from %s", reporting_week)
                       ) 
```

The peak of the outbreak was in `r date2week(find_peak(inc_week_7), floor_day = TRUE)`

```{r epicurve, message = FALSE}
# plot your epicurve as a ggplot (incidence::plot is different to base::plot)
basic_curve <- plot(inc_week_7, show_cases = TRUE, border = "black", n_breaks = nrow(inc_week_7)) + 
  scale_y_continuous(expand = c(0, 0)) +  # set origin for axes
  # add labels to axes and below chart
  epicurve_labels +
  # change visuals of dates and remove legend title
  epicurve_theme

# show your plot (stored for later use) 
basic_curve

## if the outbreak has been going on for a while, your x-axis might look messy.
# to reduce the number of labels, uncomment the below.
# you can customize the number of breaks by changing n_breaks.
#
# basic_curve + scale_x_incidence(inc_week_7, n_breaks = 6)

```


You could also plot biweekly if needed. There are also the options to do this by 
month, quarter or year. 

```{r biweekly_epicurve, message = FALSE}

# This code creates case counts for two week groups of your outbreak, overall
# As with aweek, you can change the start of your week to e.g. "2 sunday weeks"
inc_week_14 <- incidence(linelist_cleaned$date_of_onset, interval = "2 Monday weeks")

# plot your epicurve
plot(inc_week_14, show_cases = TRUE, border = "black", n_breaks = nrow(inc_week_14)) + 
  scale_y_continuous(expand = c(0,0)) +  # set origin for axes
  # add labels to axes and below chart
  epicurve_labels +
  # change visuals of dates and remove legend title
  epicurve_theme

```




You may also want to stratify by gender. 


```{r incidence_by_gender, message = FALSE}

# get counts by gender
inc_week_7_gender <- incidence(linelist_cleaned$date_of_onset, 
                               interval = "Monday week", 
                               groups = linelist_cleaned$sex)

# plot your epicurve
# here we remove the boxes around each case as it makes gender colours hard to see! (show_cases = FALSE)
plot(inc_week_7_gender, show_cases = FALSE, border = "black", n_breaks = nrow(inc_week_7_gender)) + 
  scale_y_continuous(expand = c(0,0)) +  # set origin for axes
  # add labels to axes and below chart
  epicurve_labels +
  # change visuals of dates, remove legend title and move legend to bottom
  epicurve_theme
```



You could similarly stratify by water source (or any other categorical 
variable!)

```{r incidence_by_water_source, message = FALSE}
inc_week_7_water <- incidence(linelist_cleaned$date_of_onset, 
                              interval = "Monday week", 
                              groups = linelist_cleaned$water_source)
plot(inc_week_7_water, show_cases = TRUE, border = "black", 
     n_breaks = nrow(inc_week_7_water)) + 
  scale_y_continuous(expand = c(0,0)) +  # set origin for axes
  # add labels to axes and below chart
  epicurve_labels +
  # change visuals of dates, remove legend title and move legend to bottom
  epicurve_theme
```

Alternatively, you could stratify by sex among a subset of only inpatients. 


```{r incidence_by_sex_facility, message = FALSE}
inc_week_7_sex_fac <- linelist_cleaned %>%
  filter(patient_facility_type == "Inpatient") %>%
  with(incidence(date_of_onset, interval = "Monday week", groups = sex))

plot(inc_week_7_sex_fac, show_cases = TRUE, border = "black", n_breaks = nrow(inc_week_7_sex_fac)) + 
  scale_y_continuous(expand = c(0, 0)) +  # set origin for axes
  # add labels to axes and below chart
  epicurve_labels +
  # change visuals of dates, remove legend title and move legend to bottom
  epicurve_theme
```


The below gives the attack rate per week. 

```{r attack_rate_per_week, warning = FALSE, message = FALSE}
# counts and cumulative counts by week
cases <- linelist_cleaned %>%
  arrange(date_of_onset) %>%        # arrange by date of onset
  count(epiweek, .drop = FALSE) %>% # count all epiweeks and include zero counts
  mutate(cumulative = cumsum(n))    # add a cumulative sum

# attack rate for each week
ar <- attack_rate(cases$n, population, multiplier = 10000) %>% 
  bind_cols(select(cases, epiweek), .) # add the epiweek column to table

ar %>%
  merge_ci_df(e = 4) %>% # merge the lower and upper CI into one column
  rename("Epiweek" = epiweek, 
         "Cases (n)" = cases, 
         "Population" = population, 
         "AR (per 10,000)" = ar, 
         "95%CI" = ci) %>% 
  knitr::kable(digits = 2, align = "r")
```
 


The below gives the cumulative attack rate per week. 

```{r cumulative_attack_rate_per_week}
# cumulative attack rate by week
attack_rate(cases$cumulative, population, multiplier = 10000) %>% 
  bind_cols(select(cases, epiweek), .) %>% # add the epiweek column to table
  merge_ci_df(e = 4) %>% # merge the lower and upper CI into one column
  rename("Epiweek" = epiweek, 
         "Cases (n)" = cases, 
         "Population" = population, 
         "AR (per 10,000)" = ar, 
         "95%CI" = ci) %>% 
  knitr::kable(digits = 2, align = "r")
```

The below gives case fatality ratio among inpatients per week as a proportion.

```{r cfr_per_week, warning = FALSE, message = FALSE}
# group by known outcome and case definition 
cfr <- linelist_cleaned %>%
  filter(patient_facility_type == "Inpatient") %>%
  case_fatality_rate_df(grepl("Dead", exit_status), group = epiweek)

cfr %>%
  merge_ci_df(e = 4) %>% # merge the lower and upper CI into one column
  rename("Epiweek" = epiweek, 
         "Deaths" = deaths, 
         "Cases" = population, 
         "CFR (%)" = cfr, 
         "95%CI" = ci) %>% 
  knitr::kable(digits = 2, align = "r")
```


You could plot the AR (in the population) and CFR (among inpatients only) together as line graphs by epiweek. 

```{r ar_line_graph}
ar_plot <- ggplot(ar, aes(x = week2date(epiweek) + (7 * 0.5), group = 1)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), 
              color = "blue", fill = "blue", linetype = 2, alpha = 0.2, show.legend = FALSE) +
  geom_line(aes(y = ar), color = "blue", show.legend = FALSE) +
  scale_y_continuous(expand = c(0, 0)) +  # set origin for axes
  # scale the x axis the same as the incidence curve. Expand forces it to align. 
  incidence::scale_x_incidence(inc_week_7, n_breaks = nrow(inc_week_7), expand = c(0, 7 * 1.5)) +
  # add labels to axes and below chart
  labs(x = "Calendar week", y = "AR [95% CI]", subtitle = "Attack Rate (per 10,000)") + 
  # change visuals of dates and remove legend title
  epicurve_theme
```


```{r cfr_line_graph}
cfr_plot <- ggplot(cfr, aes(x = week2date(epiweek) + (7 * 0.5), group = 1)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), 
              color = "red", fill = "red", linetype = 2, alpha = 0.2, show.legend = FALSE) +
  geom_line(aes(y = cfr), color = "red", show.legend = FALSE) +
  scale_y_continuous(expand = c(0, 0)) +  # set origin for axes
  # scale the x axis the same as the incidence curve. Expand forces it to align. 
  incidence::scale_x_incidence(inc_week_7, n_breaks = nrow(inc_week_7), expand = c(0, 7 * 1.5)) +
  # add labels to axes and below chart
  labs(x = "Calendar week", y = "CFR [95% CI]", 
       subtitle = "Case Fatality Ratio [95% CI] Among Inpatients") + 
  # change visuals of dates and remove legend title
  epicurve_theme 

```


You could then also add the AR and CFR by week on to an epicurve. 

```{r epicurve_ar_cfr, message = FALSE, fig.height = 10}
nofx <- theme(axis.text.x = element_blank(),
              axis.title.x = element_blank())
cowplot::plot_grid(
  basic_curve + nofx,
  ar_plot + nofx,
  cfr_plot,
  align = "v", # align plots vertically
  axis = "lr", # only by their left and right margins
  ncol = 1     # allow only one column
)
```


We could then also look at admissions and exits among inpatients by epiweek for operational purposes. 

```{r describe_admissions_by_epiweek, warning = FALSE}
# get counts and props of admissions by epiweek and case definition 
# include column and row totals 
tab_linelist(linelist_cleaned, epiweek, strata = case_def,
             col_total = TRUE,
             row_total = TRUE) %>% 
  select(-variable) %>%
  rename_redundant("%" = proportion) %>%
  augment_redundant(" (n)" = " n$") %>%
  kable(digits = 2)
```

The exits are among inpatients only. 

```{r describe_exits_by_epiweek, warning = FALSE}
# get counts and props of admissions by epiweek among inpatients
# include column and row totals 
linelist_cleaned %>% 
  filter(patient_facility_type == "Inpatient") %>%
  tab_linelist(epiweek, strata = exit_status2, 
               col_total = TRUE, row_total = TRUE) %>% 
  select(-variable) %>%
  rename("Week" = value) %>%
  rename_redundant("%" = proportion) %>%
  augment_redundant(" (n)" = " n$") %>%
  kable(digits = 2)
```






### Place 

*  [Across what area: one or several villages, all from same school, etc. You may want to include a map of the distribution of cases; attack rates by location]

#### Descriptive

To get a basic descriptive table of cases by region and facility, as well as by region and outcome among inpatients, see below. 


```{r describe_by_region_facility}
# get counts and props of region by facility 
# include column and row totals 

tab_linelist(linelist_cleaned, patient_origin, 
             strata = patient_facility_type,
             col_total = TRUE, row_total = TRUE) %>% 
  select(-variable) %>%
  rename("Region" = value) %>%
  rename_redundant("%" = proportion) %>%
  augment_redundant(" (n)" = " n$") %>%
  kable(digits = 2)
```




```{r describe_by_region_outcome}
# get counts and props of region by outcome among inpatients
# include column and row totals 

tab_linelist(filter(linelist_cleaned,
                    patient_facility_type == "Inpatient"),
             patient_origin, strata = exit_status2,
             col_total = TRUE, row_total = TRUE) %>% 
  select(-variable) %>%
  rename("Region" = value) %>%
  rename_redundant("%" = proportion) %>%
  augment_redundant(" (n)" = " n$") %>%
  kable(digits = 2)
```


If you do not have spatial data available, it may also be worth calculating attack rates by region. 

```{r attack_rate_by_region}

## - [ ] consider facet wrapping by an overarching unit if have many regions (e.g. by province)


cases <- count(linelist_cleaned, patient_origin) %>%   # cases for each region
  left_join(population_data_region, by = "patient_origin")    # merge population data 
# attack rate for region
ar <- attack_rate(cases$n, cases$population, multiplier = 10000) %>% 
  # add the region column to table
  bind_cols(select(cases, patient_origin), .) %>% 
  rename("Region" = patient_origin, 
         "Cases (n)" = cases, 
         "Population" = population, 
         "AR (per 10,000)" = ar, 
         "Lower 95%CI" = lower,
         "Upper 95%CI" = upper) 

ar %>% 
  merge_ci_df(e = 4) %>% # merge lower and upper CI in to one column 
  rename("95%CI" = ci) %>%  # rename single 95%CI column
  kable(digits = 2, align = "r", format.args = list(big.mark = ",")) # set thousands separator
```

You could then also plot this on a bar chart with confidence intervals. 

```{r bar_attack_rate_by_region}
# plot with the region on the x axis sorted by increasing ar
# ar value on the y axis 
ggplot(ar, aes(x = reorder(Region, `AR (per 10,000)`),
               y = `AR (per 10,000)`)) + 
  geom_bar(stat = "identity", col = "black", fill = "red") + # plot as bars (identity = as is)
  geom_errorbar(aes(ymin = `Lower 95%CI`, ymax = `Upper 95%CI`), width = 0.2) + # add CIs
  scale_y_continuous(expand = c(0,0)) +  # set origin for axes
  # add labels to axes and below chart
  labs(x = "Region", y = "AR (per 10,000)", 
       captions = paste0("Source: MSF data from ", reporting_week)) + 
  epicurve_theme
```



You could also calculate mortality rate by region (cross reference with the mortality code chunk in person section for assumptions). 

```{r mortality_rate_region}

deaths <- group_by(linelist_cleaned, patient_origin) %>%
  filter(grepl("Dead", exit_status)) %>% 
  summarise(deaths = n()) %>% # count deaths by region
  left_join(population_data_region, by = "patient_origin") # merge population data 

mortality_rate(deaths$deaths, deaths$population, multiplier = 10000) %>%
  # add the region column to table
  bind_cols(select(deaths, patient_origin), .) %>% 
  merge_ci_df(e = 4) %>% # merge the lower and upper CI into one column
  rename("Region" = patient_origin, 
         "Deaths" = deaths, 
         "Population" = population, 
         "Mortality (per 10,000)" = `mortality per 10 000`, 
         "95%CI" = ci) %>% 
  kable(digits = 2)
```




#### Maps 



```{r read_shapefiles, message=FALSE}

# DELETE THIS LINE IF YOU HAVE YOUR OWN SHAPEFILE
# generate fake shapefile
map <- gen_polygon(regions = unique(linelist_cleaned$patient_origin))

## Checklist for Shapefiles ----------------------------------------------
## 
## - [ ] Your shapefile can be a polygon or points
##          - [ ] Polygons do not need to be contiguous
## - [ ] make sure the regions named in your shapefile match the appropriate variable in your linelist!
##          - [ ] this is usually the slot ID or NAME in most shapefiles
## - [ ] Check to make sure your coordinate reference system is WGS84 (this is the standard)
##        depending on how your shapefile was made it could in a different CRS
##        this could give you trouble down the line if you want to combine plots with eg. GPS points
## - [ ] DELETE OR COMMENT OUT THE FAKE SHAPEFILE SECTION



## reading in a shapefile 
# map <- read_sf(here("mapfolder", "region.shp"))


## check the coordinate reference system (CRS)
# st_crs(map)

## set the CRS if not present using EPSG value
## this is the most commonly used 
# map <- st_set_crs(map, value = 4326) # Sets to WGS84

```

The following will plot a map based on the attack rate table. 


```{r choropleth_maps, message = FALSE, warning = FALSE}

## Checklist for plotting ----------------------------------------------
## - [ ] consider making categorical groupings of your AR or counts variable
## - [ ] merge your attack rate or counts table with your shapefile 
## - [ ] Choose the appropriate section below depending on if you are plotting polygons or points
## - [ ] Choose what variable you would like to fill (for polygons) or colour (for points) with (counts or AR)
## - [ ] DELETE OR COMMENT OUT THE SECTION YOU WONT BE USING

## create a categorical variable for plotting 
max_ar    <- max(ar$`Upper 95%CI`, na.rm = TRUE) # define your highest AR

breakers <- as.integer(c(0, # include zero as a standalone group
             seq(1, max_ar, by = max_ar/4) # 1 to maximum with four divisions
             ))
## add a categorical variable using the age_categories function 
## nb in this case we arent using ages - but it functions the same way!
ar <- mutate(ar, 
             categories = age_categories(`AR (per 10,000)`, 
                                         breakers = breakers)
             )


## join your ar or case counts based on matching shapefile names with regions in your ar table
mapsub <- left_join(map, ar, by = c("name" = "Region"))


## plotting with polygons ------------------------------------------------------

## choropleth 
## you could also fill by cases using `Cases (n)` in the fill option instead of `AR (per 10,000)`
ggplot() +
  geom_sf(data = mapsub, aes(fill = categories), col = "grey50") + # shapefile as polygon
  coord_sf(datum = NA) + # needed to avoid gridlines being drawn
  annotation_scale() + # add a scalebar
  # color the scale to be perceptually uniform 
  # drop FALSE keeps all levels 
  # name allows you to change the legend title 
  scale_fill_brewer(drop = FALSE, palette = "OrRd", name = "AR (per 10,000)") + 
  geom_sf_text(data = mapsub, aes(label = name), colour = "grey50") + # label polygons
  theme_void() # remove coordinates and axes



## plotting with points --------------------------------------------------------

# ggplot() +
#   # plot shapefile as point 
#   # shape 21 allows fill variable and colour border (e.g. black ring around circle)
#   # size allows you to make it bigger 
#   geom_sf(data = mapsub, aes(fill = categories), shape = 21, size = 5, color = "black") + 
#   coord_sf(datum = NA) + # needed to avoid gridlines being drawn
#   annotation_scale() + # add a scalebar
#     scale_fill_brewer(drop = FALSE, palette = "OrRd", name = "AR (per 10,000)") + 
 # color the scale to be perceptually uniform
#   theme_void() # remove coordinates and axes

```


You could then also throw your bar plot by region and the choropleth map, for each week, in a for-loop. 

```{r map_for_loop_epiweek, message = FALSE, warning = FALSE, fig.width = 12}


## Checklist for plotting in for-loop ------------------------------------------
## - [ ] decide if you would like to show counts, AR or categories of those
## - [ ] define appropriate breaks to ensure legend is uniform by week
## - [ ] replace `Cases (n)` and `AR (per 10,000)` or "categories", appropriately
## - [ ] consider facet wrapping by an overarching unit if have many regions (e.g. by province)



# change region variable to a factor so that zero counts can be included
linelist_cleaned$patient_origin <- as.factor(linelist_cleaned$patient_origin)

# case counts
cases <- linelist_cleaned %>% 
  group_by(epiweek) %>%
  count(patient_origin, .drop = FALSE) %>%   # cases for each week by region
  left_join(population_data_region, by = "patient_origin")    # merge population data 

# attack rate for region
ar <- attack_rate(cases$n, cases$population, multiplier = 10000) %>% 
  # add the region column to table
  bind_cols(select(cases, epiweek, patient_origin), .) %>% 
  rename("Region" = patient_origin, 
         "Cases (n)" = cases, 
         "Population" = population, 
         "AR (per 10,000)" = ar, 
         "Lower 95%CI" = lower,
         "Upper 95%CI" = upper)
max_cases <- max(cases$n, na.rm = TRUE) # define the maximum number of cases for the color palette 
max_ar    <- max(ar$`Upper 95%CI`, na.rm = TRUE)

## define breaks for standardising color palette
breakers <- as.integer(c(0, # include zero as a standalone group
             find_breaks(max_ar, breaks = 4, snap = 100) # four breaks rounded to nearest 100
             ))
## add a categorical variable using the age_categories function 
## nb in this case we arent using ages - but it functions the same way!
ar <- mutate(ar, 
             categories = age_categories(`AR (per 10,000)`, 
                                         breakers = breakers)
             )


# go through each epiweek, fiter and plot the data
for (i in unique(cases$epiweek)) {
  this_ar <- filter(ar, epiweek == i)
  
  # map 
  mapsub <- left_join(map, this_ar, by = c("name" = "Region"))
  
  # choropleth 
  map_plot <- ggplot() +
    geom_sf(data = mapsub, aes(fill = categories), col = "grey50") + # shapefile as polygon
    coord_sf(datum = NA) + # needed to avoid gridlines being drawn
    annotation_scale() + # add a scalebar
  scale_fill_brewer(drop = FALSE, 
                    palette = "OrRd", 
                    name = "AR (per 10,000)") +  # color the scale to be perceptually uniform (keep levels)
    theme_void() # remove coordinates and axes
  
  # plot with the region on the x axis sorted by increasing ar
  # ar value on the y axis 
  barplot <- ggplot(this_ar, aes(x = reorder(Region, `AR (per 10,000)`),
                                 y = `AR (per 10,000)`)) + 
    geom_bar(stat = "identity", col = "black", fill = "red") + # plot as bars (identity = as is)
    geom_errorbar(aes(ymin = `Lower 95%CI`, ymax = `Upper 95%CI`), width = 0.2) + # add CIs
    scale_y_continuous(expand = c(0, 0), limits = c(0, max_ar)) +  # set origin for axes
    # add labels to axes and below chart
    labs(x = "Region", y = "AR (per 10,000)", 
         captions = paste0("Source: MSF data from ", reporting_week)) + 
    epicurve_theme
  # combine the barplot and map plot into one
  print(
    cowplot::plot_grid(
      barplot + labs(title = paste0("Epiweek: ", i)),
      map_plot,
      nrow = 1,
      align = "h",
      axis = "tb"
    )
  )
}
```

